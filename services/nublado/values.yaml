# Default values for nublado.

# -- Override the base name for resources
nameOverride: ""

# -- Override the full name for resources (includes the release name)
fullnameOverride: ""

image:
  # -- nublado image to use
  repository: lsstsqre/jupyterlabcontroller

  # -- Pull policy for the nublado image
  pullPolicy: IfNotPresent

  # -- Tag of nublado image to use
  # @default -- The appVersion of the chart
  tag: ""

# -- Secret names to use for all Docker pulls
serviceAccount:
  # -- Name of the service account to use
  # @default -- Name based on the fullname template
  name: ""

  # -- Annotations to add to the service account
  annotations: {}

# -- Resource limits and requests for the nublado frontend pod
resources: {}

# -- Annotations for the nublado frontend pod
podAnnotations: {}

# -- Node selector rules for the nublado frontend pod
nodeSelector: {}

# -- Tolerations for the nublado frontend pod
tolerations: []

# -- Affinity rules for the nublado frontend pod
affinity: {}

ingress:
  # -- Additional annotations to add for endpoints that are authenticated.
  annotations: {}

controller:
  # -- safir settings; generically set through environment variables,
  # but we'd rather do it this way and just control all config through
  # the ConfigMap
  safir:
    # -- The application's name (not necessarily the root HTTP endpoint path)
    name: jupyterlab-controller
    # -- The application's root HTTP endpoint path
    rootEndpoint: nublado
    # -- Application run profile: "development" or "production"
    profile: development
    # -- Root name of the application's logger.
    loggerName: jupyterlabcontroller
    #
    logLevel: DEBUG
  # -- Settings for the JupyterLab controller
  lab:
    # These are the maximum CPU/memory allocations for each size
    # category.
    # The size names and ordering are taken from:
    # https://www.d20srd.org/srd/combat/movementPositionAndDistance.htm#bigandLittleCreaturesInCombat
    # Typically, we support small, medium, and large, but can range up
    # and down in instance-specific configuration.
    sizes:
      small:
        cpu: 1.0
        memory: 3Gi
      medium:
        cpu: 2.0
        memory: 6Gi
      large:
        cpu: 4.0
        memory: 12Gi
    # -- List of specifications for containers to run to commission a new user.
    initcontainers: []
    # Each member of the list should set a container `name`, `image`, and
    # `privileged`, and may contain `volumes` (defined immediately below).
    # If `privileged` is true, the container will run as root with
    # `allowPrivilegeEscalation` true; otherwise it will (by convention)
    # run as user 1000.
    # - name: farthing
    #   image: lsstsqre/farthing
    #   privileged: false
    # - name: provisionator
    #   image: lsstsqre/provisionator
    #   privileged: true
    #   volumes:
    #   - containerPath: /home
    #     serverPath: /share1/home
    #     server: 10.13.105.122
    #     mode: rw
    # -- Volumes defined to user lab pods
    volumes:
    - containerPath: /home
      serverPath: /share1/home
      server: 10.13.105.122
      mode: rw
    - containerPath: /project
      serverPath: /share1/project
      server: 10.13.105.122
      mode: ro
    - containerPath: /scratch
      serverPath: /share1/scratch
      server: 10.13.105.122
      mode: rw
    # -- Environment variables for user lab pods, common to all lab pods
    # in this RSP instance.
    env:
      API_ROUTE: /api
      # AUTO_REPO_BRANCH: "prod"  # No longer needed
      AUTO_REPO_SPECS: "https://github.com/lsst-sqre/system-test@prod,https://github.com/rubin-dp0/tutorial-notebooks@prod"
      # AUTO_REPO_URLS: "https://github.com/lsst-sqre/system-test,https://github.com/rubin-dp0/tutorial-notebooks"  # No longer needed
      CULL_KERNEL_IDLE_TIMEOUT: "432000"  # These might be set from group?
      CULL_KERNEL_CONNECTED: "True"
      CULL_KERNEL_INTERVAL: "300"
      DAF_BUTLER_REPOSITORY_INDEX: "s3://butler-us-central1-repo-locations/data-repos.yaml"
      FIREFLY_ROUTE: /portal/app
      HUB_ROUTE: /nb/hub
      # JS9_ROUTE: /js9  # No longer used?
      JUPYTERHUB_ADMIN_ACCESS: "1"  # Do we need this?!?
      JUPYTERHUB_API_URL: http://hub.nublado2:8081/nb/hub/api
      JUPYTERHUB_BASE_URL: /nb/
      JUPYTERHUB_DEFAULT_URL: /lab
      JUPYTERHUB_OAUTH_CLIENT_ALLOWED_SCOPES: '[]' # needed?
      NO_ACTIVITY_TIMEOUT: "432000"  # Also from group?
      NO_SUDO: "TRUE"
      S3_ENDPOINT_URL: "https://storage.googleapis.com"
      SODA_ROUTE: /api/image/soda
      TAP_ROUTE: /api/tap
      # WORKFLOW_ROUTE: /wf  # No longer used
      # Note that other environment variables will be injected by the
      # Lab controller (to match KubeSpawner's behavior).  These
      # must be calculated from other Lab-spawn-time values, and
      # include:
      # ACCESS_TOKEN
      # CPU_LIMIT
      # DEBUG
      # EXTERNAL_GID
      # EXTERNAL_GROUPS
      # JPY_API_TOKEN
      # JUPYTERHUB_ACTIVITY_URL
      # JUPYTERHUB_CLIENT_ID
      # JUPYTERHUB_OAUTH_ACCESS_SCOPES
      # JUPYTERHUB_OAUTH_CALLBACK_URL
      # JUPYTERHUB_OAUTH_SCOPES  # Alias for JUPYTERHUB_OAUTH_ACCESS_SCOPES
      # JUPYTERHUB_SERVICE_PREFIX
      # JUPYTERHUB_SERVICE_URL
      # JUPYTERHUB_USER
      # JUPYTER_IMAGE
      # JUPYTER_IMAGE_SPEC  # Alias for JUPYTER_IMAGE
      # MEM_GUARANTEE  # in bytes
      # MEM_LIMIT      # in bytes
      # RESET_USER_ENV
      # Additionally, some environment variables will be set from the
      # secrets below.  These will be paths to injected credential
      # files.
      # EXTERNAL_INSTANCE_URL is a special case: it's
      # constant-per-instance, but you can't template values files
    secrets: []
    #  secretRef: credentials
    #  secretKey: butler-credentials
    # -- Files to be mounted as ConfigMaps inside the user lab pod.
    # Some of these will require modification.  Those are noted with
    # modify: true, and the file name will be the unique key directing
    # how the Lab controller is to modify it.
    files:
      /etc/passwd:
        modify: true
        contents: |
          root:x:0:0:root:/root:/bin/bash
          bin:x:1:1:bin:/bin:/sbin/nologin
          daemon:x:2:2:daemon:/sbin:/sbin/nologin
          adm:x:3:4:adm:/var/adm:/sbin/nologin
          lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
          sync:x:5:0:sync:/sbin:/bin/sync
          shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
          halt:x:7:0:halt:/sbin:/sbin/halt
          mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
          operator:x:11:0:operator:/root:/sbin/nologin
          games:x:12:100:games:/usr/games:/sbin/nologin
          ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
          tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin
          dbus:x:81:81:System message bus:/:/sbin/nologin
          nobody:x:99:99:Nobody:/:/sbin/nologin
          systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
          lsst_lcl:x:1000:1000::/home/lsst_lcl:/bin/bash
      /etc/group:
        modify: true
        contents: |
          root:x:0:
          bin:x:1:
          daemon:x:2:
          sys:x:3:
          adm:x:4:
          tty:x:5:
          disk:x:6:
          lp:x:7:
          mem:x:8:
          kmem:x:9:
          wheel:x:10:
          cdrom:x:11:
          mail:x:12:
          man:x:15:
          dialout:x:18:
          floppy:x:19:
          games:x:20:
          utmp:x:22:
          tape:x:33:
          utempter:x:35:
          video:x:39:
          ftp:x:50:
          lock:x:54:
          tss:x:59:
          audio:x:63:
          dbus:x:81:
          screen:x:84:
          nobody:x:99:
          users:x:100:
          systemd-journal:x:190:
          systemd-network:x:192:
          cgred:x:997:
          ssh_keys:x:998:
          input:x:999:
      /opt/lsst/software/jupyterlab/lsst_dask.yml:
        modify: false
        contents: |
          # No longer used, but preserves compatibility with runlab.sh
          dask_worker.yml: |
            enabled: false
      /opt/lsst/software/jupyterlab/panda:
        modify: false
        contents: |
          # Licensed under the Apache License, Version 2.0 (the "License");
          # You may not use this file except in compliance with the License.
          # You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
          #
          # Authors:
          # - Wen Guan, <wen.guan@cern.ch>, 2020
          [common]
          # if logdir is configured, idds will write to idds.log in this directory.
          # else idds will go to stdout/stderr.
          # With supervisord, it's good to write to stdout/stderr, then supervisord can manage and rotate logs.
          # logdir = /var/log/idds
          loglevel = INFO
          [rest]
          host = https://iddsserver.cern.ch:443/idds
          #url_prefix = /idds
          #cacher_dir = /tmp
          cacher_dir = /data/idds
    # # -- Secrets for injection into user lab pods.  The name is again
    # # the unique key that allows the Lab Controller to create the
    # # contents.  Since these are stored as secrets, they will be created
    # # from whole cloth, rather than modified from a base template.
    # # If 'env' is specified, the mount_path will be stored in that environment
    # # variable.
    # secrets:
    # - name: aws-credentials.ini
    #   mount_path: /opt/lsst/software/jupyterlab/butler-secret/aws-credentials.ini
    #   env: AWS_SHARED_CREDENTIALS_FILE

    # - name: butler-gcs-idf-creds.json
    #   mount_path: /opt/lsst/software/jupyterlab/butler-secret/butler-gcs-idf-creds.json
    #   env: GOOGLE_APPLICATION_CREDENTIALS
    # - name: butler-hmac-idf-creds.json
    #   mount_path: /opt/lsst/software/jupyterlab/butler-secret/butler-hmac-idf-creds.json
    # - name: postgres-credentials.txt
    #   mount_path: /opt/lsst/software/jupyterlab/butler-secret/postgres-credentials.txt
    #   env: PGPASSFILE
  images:
    # -- config from sqr-066
    registry: lighthouse.ceres
    docker:
      repository: library/sketchbook
    recommendedTag: recommended
    numReleases: 1
    numWeeklies: 2
    numDailies: 3
  # -- Runtime config will be filled in on initialization
  runtime:
    path: ""
    namespace: ""
    instanceUrl: ""

# The following will be set by parameters injected by Argo CD and should not
# be set in the individual environment values files.
global:
  # -- Base URL for the environment
  # @default -- Set by Argo CD
  baseUrl: ""

  # -- Host name for ingress
  # @default -- Set by Argo CD
  host: ""

  # -- Base path for Vault secrets
  # @default -- Set by Argo CD
  vaultSecretsPath: ""
