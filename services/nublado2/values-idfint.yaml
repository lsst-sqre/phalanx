jupyterhub:
  hub:
    resources:
      requests:
        cpu: "2"
        memory: 3Gi
  ingress:
    hosts: ["data-int.lsst.cloud"]
    annotations:
      nginx.ingress.kubernetes.io/auth-signin: "https://data-int.lsst.cloud/login"
config:
  base_url: "https://data-int.lsst.cloud"
  butler_secret_path: "secret/k8s_operator/data-int.lsst.cloud/butler-secret"
  pull_secret_path: "secret/k8s_operator/data-int.lsst.cloud/pull-secret"
  cachemachine_image_policy: "desired"
  lab_environment:
    PGPASSFILE: "/opt/lsst/software/jupyterlab/butler-secret/postgres-credentials.txt"
    AWS_SHARED_CREDENTIALS_FILE: "/opt/lsst/software/jupyterlab/butler-secret/aws-credentials.ini"
    S3_ENDPOINT_URL: "https://storage.googleapis.com"
    GOOGLE_APPLICATION_CREDENTIALS: "/opt/lsst/software/jupyterlab/butler-secret/butler-gcs-idf-creds.json"
    DAF_BUTLER_REPOSITORY_INDEX: "s3://butler-us-central1-repo-locations/data-int-repos.yaml"
    AUTO_REPO_URLS: https://github.com/lsst-sqre/system-test,https://github.com/rubin-dp0/tutorial-notebooks
    AUTO_REPO_BRANCH: prod
    AUTO_REPO_SPECS: https://github.com/lsst-sqre/system-test@prod,https://github.com/rubin-dp0/tutorial-notebooks@prod
    PANDA_AUTH: oidc
    PANDA_VERIFY_HOST: "off"
    PANDA_AUTH_VO: Rubin
    PANDA_URL_SSL: https://pandaserver-doma.cern.ch:25443/server/panda
    PANDA_URL: http://pandaserver-doma.cern.ch:25080/server/panda
    IDDS_CONFIG: /opt/lsst/software/jupyterlab/panda/idds.cfg.client.template
    PANDA_CONFIG_ROOT: "~"
  sizes:
    - name: Small
      cpu: 1
      ram: 3072M
    - name: Medium
      cpu: 2
      ram: 6144M
    - name: Large
      cpu: 4
      ram: 12288M
    - name: Huge
      cpu: 8
      ram: 24576M
  volumes:
    - name: home
      nfs:
        path: /share1/home
        server: 10.22.240.130
    - name: project
      nfs:
        path: /share1/project
        server: 10.22.240.130
    - name: scratch
      nfs:
        path: /share1/scratch
        server: 10.22.240.130
  volume_mounts:
    - name: home
      mountPath: /home
    - name: project
      mountPath: /project
    - name: scratch
      mountPath: /scratch
  # Workaround to impose resource quotas at IDF
  user_resources_template: |
    - apiVersion: v1
      kind: Namespace
      metadata:
        name: "{{ user_namespace }}"
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: group
        namespace: "{{ user_namespace }}"
      data:
        group: |
          root:x:0:
          bin:x:1:
          daemon:x:2:
          sys:x:3:
          adm:x:4:
          tty:x:5:
          disk:x:6:
          lp:x:7:
          mem:x:8:
          kmem:x:9:
          wheel:x:10:
          cdrom:x:11:
          mail:x:12:
          man:x:15:
          dialout:x:18:
          floppy:x:19:
          games:x:20:
          tape:x:33:
          video:x:39:
          ftp:x:50:
          lock:x:54:
          audio:x:63:
          nobody:x:99:
          users:x:100:
          utmp:x:22:
          utempter:x:35:
          input:x:999:
          systemd-journal:x:190:
          systemd-network:x:192:
          dbus:x:81:
          ssh_keys:x:998:
          lsst_lcl:x:1000:{{ user }}
          tss:x:59:
          cgred:x:997:
          screen:x:84:
          jovyan:x:768:{{ user }}
          provisionator:x:769:
          {{user}}:x:{{uid}}:{% for group in groups %}
          {{ group.name }}:x:{{ group.id }}:{{ user }}{% endfor %}
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: gshadow
        namespace: "{{ user_namespace }}"
      data:
        gshadow: |
          root:!::
          bin:!::
          daemon:!::
          sys:!::
          adm:!::
          tty:!::
          disk:!::
          lp:!::
          mem:!::
          kmem:!::
          wheel:!::
          cdrom:!::
          mail:!::
          man:!::
          dialout:!::
          floppy:!::
          games:!::
          tape:!::
          video:!::
          ftp:!::
          lock:!::
          audio:!::
          nobody:!::
          users:!::
          utmp:!::
          utempter:!::
          input:!::
          systemd-journal:!::
          systemd-network:!::
          dbus:!::
          ssh_keys:!::
          lsst_lcl:!::{{ user }}
          tss:!::
          cgred:!::
          screen:!::
          jovyan:!::{{ user }}
          provisionator:!::
          {{ user }}:!::{% for g in groups %}
          {{ g.name }}:!::{{ user }}{% endfor %}
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: passwd
        namespace: "{{ user_namespace }}"
      data:
        passwd: |
          root:x:0:0:root:/root:/bin/bash
          bin:x:1:1:bin:/bin:/sbin/nologin
          daemon:x:2:2:daemon:/sbin:/sbin/nologin
          adm:x:3:4:adm:/var/adm:/sbin/nologin
          lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
          sync:x:5:0:sync:/sbin:/bin/sync
          shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
          halt:x:7:0:halt:/sbin:/sbin/halt
          mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
          operator:x:11:0:operator:/root:/sbin/nologin
          games:x:12:100:games:/usr/games:/sbin/nologin
          ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
          nobody:x:99:99:Nobody:/:/sbin/nologin
          systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
          dbus:x:81:81:System message bus:/:/sbin/nologin
          lsst_lcl:x:1000:1000::/home/lsst_lcl:/bin/bash
          tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin
          provisionator:x:769:769:Lab provisioning user:/home/provisionator:/bin/bash
          {{ user }}:x:{{ uid }}:{{ uid }}::/home/{{ user }}:/bin/bash
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: shadow
        namespace: "{{ user_namespace }}"
      data:
        shadow: |
          root:*:18000:0:99999:7:::
          bin:*:18000:0:99999:7:::
          daemon:*:18000:0:99999:7:::
          adm:*:18000:0:99999:7:::
          lp:*:18000:0:99999:7:::
          sync:*:18000:0:99999:7:::
          shutdown:*:18000:0:99999:7:::
          halt:*:18000:0:99999:7:::
          mail:*:18000:0:99999:7:::
          operator:*:18000:0:99999:7:::
          games:*:18000:0:99999:7:::
          ftp:*:18000:0:99999:7:::
          nobody:*:18000:0:99999:7:::
          systemd-network:*:18000:0:99999:7:::
          dbus:*:18000:0:99999:7:::
          lsst_lcl:*:18000:0:99999:7:::
          tss:*:18000:0:99999:7:::
          provisionator:*:18000:0:99999:7:::
          {{user}}:*:18000:0:99999:7:::
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: dask
        namespace: "{{ user_namespace }}"
      data:
        dask_worker.yml: |
          {{ dask_yaml | indent(6) }}
    # When we break out the resources we should make this per-instance
    #  configurable.
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: idds-config
        namespace: "{{ user_namespace }}"
      data:
        idds.cfg.client.template: |
          # Licensed under the Apache License, Version 2.0 (the "License");
          # You may not use this file except in compliance with the License.
          # You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
          #
          # Authors:
          # - Wen Guan, <wen.guan@cern.ch>, 2020
          [common]
          # if logdir is configured, idds will write to idds.log in this directory.
          # else idds will go to stdout/stderr.
          # With supervisord, it's good to write to stdout/stderr, then supervisord can manage and rotate logs.
          # logdir = /var/log/idds
          loglevel = INFO
          [rest]
          host = https://iddsserver.cern.ch:443/idds
          #url_prefix = /idds
          #cacher_dir = /tmp
          cacher_dir = /data/idds
    - apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: "{{ user }}-serviceaccount"
        namespace: "{{ user_namespace }}"
      imagePullSecrets:
      - name: pull-secret
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: Role
      metadata:
        name: "{{ user }}-role"
        namespace: "{{ user_namespace }}"
      rules:
      # cf https://kubernetes.dask.org/en/latest/kubecluster.html
        - apiGroups: [""]
          resources: ["pods", "services"]
          verbs: ["create", "delete", "get", "list", "watch"]
        - apiGroups: [""]
          resources: ["pods/log"]
          verbs: ["get","list"]
        - apiGroups: ["policy"]
          resources: ["poddisruptionbudgets"]
          verbs: ["create", "delete", "get", "list", "watch"]
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: "{{ user }}-rolebinding"
        namespace: "{{ user_namespace }}"
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: Role
        name: "{{ user }}-role"
      subjects:
        - kind: ServiceAccount
          name: "{{ user }}-serviceaccount"
          namespace: "{{ user_namespace }}"
    - apiVersion: ricoberger.de/v1alpha1
      kind: VaultSecret
      metadata:
        name: butler-secret
        namespace: "{{ user_namespace }}"
      spec:
        path: "{{ butler_secret_path }}"
        type: Opaque
    - apiVersion: ricoberger.de/v1alpha1
      kind: VaultSecret
      metadata:
        name: pull-secret
        namespace: "{{ user_namespace }}"
      spec:
        path: "{{ pull_secret_path }}"
        type: kubernetes.io/dockerconfigjson
    - apiVersion: v1
      kind: ResourceQuota
      metadata:
        name: user-quota
        namespace: "{{ user_namespace }}"
      spec:
        hard:
          limits.cpu: 9
          limits.memory: 27Gi

vault_secret_path: "secret/k8s_operator/data-int.lsst.cloud/nublado2"

pull-secret:
  enabled: true
  path: "secret/k8s_operator/data-int.lsst.cloud/pull-secret"
