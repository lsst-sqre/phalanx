{{- if .Values.config.updateSchema -}}
apiVersion: batch/v1
kind: Job
metadata:
  name: "vo-cutouts-schema-update"
  annotations:
  annotations:
    helm.sh/hook: "pre-install,pre-upgrade"
    helm.sh/hook-delete-policy: "hook-succeeded"
    helm.sh/hook-weight: "1"
  labels:
    {{- include "vo-cutouts.labels" . | nindent 4 }}
spec:
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "vo-cutouts.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: "schema-update"
        vo-cutouts-redis-client: "true"
    spec:
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- if .Values.cloudsql.enabled }}
      serviceAccountName: "vo-cutouts"
      {{- else }}
      automountServiceAccountToken: false
      {{- end }}
      containers:
        {{- if .Values.cloudsql.enabled }}
        - name: "cloud-sql-proxy"
          # Running the sidecar as normal causes it to keep running and thus
          # the Pod never exits, the Job never finishes, and the hook blocks
          # the sync. Have the main pod signal the sidecar by writing to a
          # file on a shared emptyDir file system, and use a simple watcher
          # loop in shell in the sidecar container to terminate the proxy when
          # the main container finishes.
          #
          # Based on https://stackoverflow.com/questions/41679364/
          command:
            - "/bin/sh"
            - "-c"
          args:
            - |
              /cloud_sql_proxy -ip_address_types=PRIVATE -log_debug_stdout=true -structured_logs=true -instances={{ required "cloudsql.instanceConnectionName must be specified" .Values.cloudsql.instanceConnectionName }}=tcp:5432 &
              PID=$!
              while true; do
                if [[ -f "/lifecycle/main-terminated" ]]; then
                  kill $PID
                  exit 0
                fi
                sleep 1
              done
          image: "{{ .Values.cloudsql.image.repository }}:{{ .Values.cloudsql.image.tag }}{{ .Values.cloudsql.image.schemaUpdateTagSuffix }}"
          imagePullPolicy: {{ .Values.cloudsql.image.pullPolicy | quote }}
          {{- with .Values.cloudsql.resources }}
          resources:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - "all"
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 65532
            runAsGroup: 65532
          volumeMounts:
            - name: "lifecycle"
              mountPath: "/lifecycle"
        {{- end }}
        - name: "vo-cutouts"
          command:
            - "/bin/sh"
            - "-c"
            - |
              vo-cutouts update-schema
              touch /lifecycle/main-terminated
          env:
            - name: "CUTOUT_ARQ_QUEUE_PASSWORD"
              valueFrom:
                secretKeyRef:
                  name: "vo-cutouts"
                  key: "redis-password"
            - name: "CUTOUT_DATABASE_PASSWORD"
              valueFrom:
                secretKeyRef:
                  name: "vo-cutouts"
                  key: "database-password"
          envFrom:
            - configMapRef:
                name: "vo-cutouts"
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy | quote }}
          {{- with .Values.resources }}
          resources:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - "all"
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: "lifecycle"
              mountPath: "/lifecycle"
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      restartPolicy: "Never"
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      volumes:
        - name: "lifecycle"
          emptyDir: {}
{{- end }}
