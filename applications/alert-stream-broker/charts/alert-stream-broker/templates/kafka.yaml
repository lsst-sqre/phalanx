apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: controller
  labels:
    strimzi.io/cluster: {{ .Values.cluster.name }}
spec:
  replicas: {{ .Values.kafka.replicas }}
  roles:
    - controller
  storage:
    type: jbod
    volumes:
    - id: 0
      type: persistent-claim
      size: {{ .Values.kafkaController.storage.size }}
      class: {{ .Values.kafkaController.storage.storageClassName }}
      deleteClaim: false
  {{- with .Values.kafkaController.resources }}
  resources:
    {{- toYaml . | nindent 6 }}
  {{- end }}
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: kafka
  labels:
    strimzi.io/cluster: {{ .Values.cluster.name }}
  annotations:
    strimzi.io/next-node-ids: "[0-99]"
spec:
  replicas: {{ .Values.kafka.replicas }}
  roles:
    - broker
  storage:
    type: jbod
    volumes:
    - id: 0
      type: persistent-claim
      size: {{ .Values.kafka.storage.size }}
      {{- if .Values.kafka.storage.storageClassName }}
      class: {{ .Values.kafka.storage.storageClassName }}
      {{- end}}
      deleteClaim: false
  {{- with .Values.kafka.resources }}
  resources:
    {{- toYaml . | nindent 6 }}
  {{- end }}
---
apiVersion: kafka.strimzi.io/{{ .Values.strimziAPIVersion }}
kind: Kafka
metadata:
  name: {{ .Values.cluster.name }}
  annotations:
    strimzi.io/kraft: enabled
    strimzi.io/node-pools: enabled
spec:
  {{- if .Values.kafkaExporter.enabled }}
  kafkaExporter:
    groupRegex: {{ .Values.kafkaExporter.groupRegex }}
    topicRegex: {{ .Values.kafkaExporter.topicRegex }}
    enableSaramaLogging: {{ .Values.kafkaExporter.enableSaramaLogging }}
    logging: {{ .Values.kafkaExporter.logLevel }}
    template:
      deployment:
        metadata:
          annotations:
            prometheus.io/scrape: 'true'
      pod:
        metadata:
          annotations:
            prometheus.io/scrape: 'true'
  {{- end }}

  kafka:
    {{- if .Values.kafka.prometheusScrapingEnabled }}
    template:
      pod:
        metadata:
          annotations:
            prometheus.io/scrape: 'true'
    {{- end }}
    version: {{ .Values.kafka.version }}
    replicas: {{ .Values.kafka.replicas }}
    resources:
      requests:
        memory: 16Gi
        cpu: "4"
      limits:
        memory: 32Gi
        cpu: "8"
    listeners:
      - name: internal
        port: 9092
        type: internal
        tls: true
        authentication:
          type: tls
      - name: tls  # Used by the schema registry; it has a fixed name it expects
        port: 9093
        type: internal
        tls: true
        authentication:
          type: tls
      - name: external
        port: 9094
        type: loadbalancer
        tls: {{ .Values.kafka.externalListener.tls.enabled}}
        authentication:
          type: scram-sha-512
        configuration:
          {{- /*

          This is complicated looking, but that's just because these are all
          optional parameters. They're optional because we don't actually know
          the right IP addresses to use on a fresh deployment.

          The LoadBalancer Service type triggers automatic creation of a cloud
          load balancer, which will get provisioned with some IP address that
          we don't actually choose - it's picked for us. Once that has been
          done, these options make it possible to pin the IP address: we can
          request the actual IP that we already have. This is important because
          it lets us configure a DNS record, associating a hostname with that
          pinned IP address.

          */}}
          bootstrap:

            {{- if .Values.kafka.externalListener.bootstrap.ip }}
            loadBalancerIP: {{ .Values.kafka.externalListener.bootstrap.ip }}
            {{- end }}

            {{- with .Values.kafka.externalListener.bootstrap.annotations }}
            annotations:
              {{- toYaml . | nindent 14 }}
            {{- end }}

          {{- if .Values.kafka.externalListener.brokers }}
          brokers:
          {{- range $broker := .Values.kafka.externalListener.brokers }}
            - broker: {{ $broker.broker }}
              loadBalancerIP: {{ $broker.ip }}
              advertisedHost: {{ $broker.host }}
              advertisedPort: 9094
              annotations:
                annotations: {{ toYaml $broker.annotations | nindent 16 }}
          {{- end }}
          {{- end }}
          {{- if and (.Values.kafka.externalListener.tls.enabled) (.Values.kafka.externalListener.bootstrap.host) }}
          brokerCertChainAndKey:
            secretName: {{ .Values.cluster.name }}-external-tls
            certificate: tls.crt
            key: tls.key
          {{- end }}

    authorization:
      type: simple
{{- if .Values.superusers }}
      superUsers:
{{- range .Values.superusers }}
        - {{ . }}
{{- end }}
{{- end }}

    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      message.max.bytes: 4194304 # 8 Megabytes. For testing purposes only.
      ssl.client.auth: required
      {{- range $key, $value := .Values.kafka.config }}
      {{ $key }}: {{ $value }}
      {{- end }}
    storage:
      type: jbod
      volumes:
        # Note that storage is configured per replica. If there are 3 replicas,
        # and 2 volumes in this array, each replica will get 2
        # PersistentVolumeClaims for the configured size, for a total of 6
        # volumes.
      - id: 0
        type: persistent-claim
        size: {{ .Values.kafka.storage.size }}
        class: {{ .Values.kafka.storage.storageClassName }}
        deleteClaim: false

    template:
      pod:
        {{- if .Values.kafka.nodePool.tolerations }}
        tolerations:
          {{- range $tol := .Values.kafka.nodePool.tolerations }}
          - key: {{ $tol.key }}
            operator: "Equal"
            value: {{ $tol.value }}
            effect: {{ $tol.effect }}
          {{- end }}
        {{- end }}

        {{- if .Values.kafka.nodePool.affinities }}
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              {{- range $affinity := .Values.kafka.nodePool.affinities }}
              - weight: 1
                preference:
                  matchExpressions:
                      - key: {{ $affinity.key }}
                        operator: In
                        values: [{{ $affinity.value }}]
              {{- end }}
        {{- end }}

  entityOperator:
    topicOperator: {}
    userOperator: {}
