# Mostly based on the Strimzi Kafka MirrorMaker2 example
# configuration for handling high volumes of messages.
{{ if .Values.mirrormaker2.enabled }}
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaMirrorMaker2
metadata:
  name:  {{ .Values.cluster.name }}
spec:
  version: {{ .Values.kafka.version }}
  replicas:  {{ .Values.mirrormaker2.replicas }}
  # In Sasquatch MirrorMaker2 is deployed on the target cluster
  # and replicates data from the source cluster.
  connectCluster: {{ .Values.mirrormaker2.target.alias }}
  clusters:
  - alias: {{ .Values.mirrormaker2.source.alias }}
    bootstrapServers: {{ .Values.mirrormaker2.source.bootstrapServer }}
    tls: {}
    # The external kafka listeneres in Sasquatch use scram-sha-512 authentication
    # Use the replicator Kafka user to authenticate against the Kafka source cluster.
    # Not the same secret with the replicator password must exist in both the source
    # and the target clusters.
    authentication:
      type: scram-sha-512
      username: replicator
      passwordSecret:
        secretName: sasquatch
        password: replicator-password
  - alias: {{ .Values.mirrormaker2.target.alias }}
    # For the Kafka target cluster, use the internal listener with tls encryption and mutual tls authentication.
    bootstrapServers: {{ .Values.cluster.name }}-kafka-bootstrap:9093
    tls:
      trustedCertificates:
        - secretName: {{ .Values.cluster.name }}-cluster-ca-cert
          certificate: ca.crt
    authentication:
      type: tls
      certificateAndKey:
        secretName: {{ .Values.cluster.name }}-connect
        certificate: user.crt
        key: user.key
    config:
      # This should be enough time for the sent messages to be acknowledged
      # by the brokers and offset data committed.
      offset.flush.timeout.ms: 10000
  mirrors:
  - sourceCluster: {{ .Values.mirrormaker2.source.alias }}
    targetCluster: {{ .Values.mirrormaker2.target.alias }}
    sourceConnector:
      tasksMax: 128
      autoRestart:
        enabled: true
      config:
        replication.factor: 3
        offset-syncs.topic.replication.factor: 3
        # The location (source/target) of the offset-syncs topic.
        # Default is source. If MirrorMaker2 is enabled on multiple target clusters replicating from the same source cluster,
        # set this to target.
        offset-syncs.topic.location: {{ .Values.mirrormaker2.replication.offsetSyncsTopicLocation }}
        # Dot not replicate topic ACLs configuration.
        sync.topic.acls.enabled: "false"
        # The frequency to check for new topics.
        refresh.topics.interval.seconds: 60
        # Policy to define the remote topic naming convention.
        # The default is to preserve topic names in the target cluster.
        # To add the source cluster alias as a prefix to the topic name, use replication.policy.separator="." and replication.policy.class="org.apache.kafka.connect.mirror.DefaultReplicationPolicy"
        replication.policy.separator: {{ .Values.mirrormaker2.replication.policy.separator }}
        replication.policy.class: {{ .Values.mirrormaker2.replication.policy.class }}
        # Handling high volumes of messages
        # By increasing the batch size, produce requests are delayed and more messages are
        # added to the batch and sent to brokers at the same time.
        # This can improve throughput when you have just a few topic partitions that
        # handle large numbers of messages.
        producer.override.batch.size: 524288
        # Use linger.ms to add a wait time in milliseconds to delay produce requests when
        # producer load decreases.
        # The delay means that more records can be added to batches if they are under the
        # maximum batch size.
        producer.override.linger.ms: 100
        # Accept larger messages.
        # See also message.max.bytes broker configuration.
        producer.max.request.size: 10485760
        producer.buffer.memory: 10485760
        # Increase the maximum number of messages fetched per request.
        # This can improve throughput when you have just a few topic partitions that
        # handle large numbers of messages.
        consumer.fetch.max.bytes: 52428800
        consumer.max.partition.fetch.bytes: 1048576
        consumer.max.poll.records: 500
        # Increase request timeout
        producer.request.timeout.ms: 240000
        consumer.request.timeout.ms: 240000
        consumer.auto.offset.reset: {{ .Values.mirrormaker2.replication.offset }}
    heartbeatConnector:
      autoRestart:
        enabled: true
      config:
        heartbeats.topic.replication.factor: 3
    # Topic replication from the source cluster defined as a comma-separated list
    # or regular expression pattern.
    topicsPattern: {{ .Values.mirrormaker2.source.topicsPattern }}
  resources:
    requests:
      cpu: {{ .Values.mirrormaker2.resources.requests.cpu | quote }}
      memory: {{ .Values.mirrormaker2.resources.requests.memory | quote }}
    limits:
      cpu: {{ .Values.mirrormaker2.resources.limits.cpu | quote }}
      memory: {{ .Values.mirrormaker2.resources.limits.memory | quote }}
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: {{ .Values.cluster.name }}-connect
  labels:
    strimzi.io/cluster: {{ .Values.cluster.name }}
spec:
  authentication:
    type: tls
  authorization:
    type: simple
    acls:
      - resource:
          type: group
          name: {{ .Values.cluster.name }}-connect
        operations:
          - Read
      - resource:
          type: group
          name: "*"
          patternType: literal
        operations:
          - All
      - resource:
          type: topic
          name: "*"
          patternType: literal
        type: allow
        host: "*"
        operations:
          - All
{{ end }}
