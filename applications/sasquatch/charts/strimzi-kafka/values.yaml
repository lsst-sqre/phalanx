# Default values for Kafka used in Sasquatch.

cluster:
  # -- Name used for the Kafka cluster, and used by Strimzi for many
  # annotations
  name: sasquatch

  # -- Site wide label required for gathering Prometheus metrics if they are
  # enabled
  monitorLabel: {}

kafka:
  # -- Version of Kafka to deploy
  version: "3.8.0"

  # -- Number of Kafka broker replicas to run
  replicas: 3

  # -- The minimum number of in-sync replicas that must be available for the producer to successfully send records
  # Cannot be greater than the number of replicas.
  minInsyncReplicas: 2

  config:
    # -- Number of minutes for a consumer group's offsets to be retained
    # @default -- 4320 minutes (3 days)
    offsets.retention.minutes: 4320

    # -- Number of days for a topic's data to be retained
    # @default -- 4320 minutes (3 days)
    log.retention.minutes: 4320

    # -- The largest record batch size allowed by Kafka
    message.max.bytes: 10485760

    # -- The number of bytes of messages to attempt to fetch for each partition
    replica.fetch.max.bytes: 10485760

  metricsConfig:
    # -- Whether metric configuration is enabled
    enabled: false

  listeners:
    plain:
      # -- Whether internal plaintext listener is enabled
      enabled: false

    tls:
      # -- Whether internal TLS listener is enabled
      enabled: false

    external:
      # -- Whether external listener is enabled
      enabled: false

  externalListener:
    tls:
      # -- Whether TLS encryption is enabled
      enabled: false

      # -- Name of a ClusterIssuer capable of provisioning a TLS certificate
      # for the broker
      certIssuerName: "letsencrypt-dns"

    bootstrap:
      # Load balancer IP configuration
      #
      # The loadbalancer is requested with the IP address specified in this
      # field.  This feature depends on whether the underlying cloud provider
      # supports specifying the loadBalancerIP when a load balancer is
      # created.  This field is ignored if the cloud provider does not support
      # the feature.
      #
      # Once the IP address is provisioned this option make it possible to pin
      # the IP address.  We can request the same IP next time it is
      # provisioned. This is important because it lets us configure a DNS
      # record, associating a hostname with that pinned IP address.
      #
      # -- Request this load balancer IP. See `values.yaml` for more
      # discussion
      # @default -- Do not request a load balancer IP
      loadBalancerIP: ""

      # -- Name used for TLS hostname verification
      # @default -- Do not configure TLS
      host: ""

      # -- Annotations that will be added to the Ingress, Route, or Service
      # resource
      annotations: {}

    # -- Brokers configuration. _host_ is used in the brokers'
    # advertised.brokers configuration and for TLS hostname verification.  The
    # format is a list of maps.
    brokers: []
    # For example:
    # brokers:
    #   - broker: 0
    #     loadBalancerIP: "192.168.1.1"
    #     host: broker-0.example
    #     annotations:
    #       metallb.universe.tf/address-pool: sdf-dmz
    #   - broker: 1
    #     loadBalancerIP: "192.168.1.2"
    #     host: broker-1.example
    #     annotations:
    #       metallb.universe.tf/address-pool: sdf-dmz

controller:
  # -- Enable node pool for the kafka controllers
  enabled: false

  # -- IDs to assign to the controllers
  nodeIds: "[3,4,5]"

  storage:
    # -- Storage size for the controllers
    size: 20Gi

    # -- Storage class to use when requesting persistent volumes
    # @default -- None, use the default storage class
    storageClassName: ""

  # -- Affinity for controller pod assignment
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: "app.kubernetes.io/name"
                operator: In
                values:
                  - kafka
          topologyKey: "kubernetes.io/hostname"

  # -- Tolerations for controller pod assignment
  tolerations: []

  # -- Kubernetes resources for the controllers
  resources:
    requests:
      memory: 2Gi
      cpu: 500m
    limits:
      memory: 4Gi
      cpu: "1"

broker:
  # -- Enable node pool for the kafka brokers
  enabled: false

  # -- Node pool name
  name: kafka

  # -- IDs to assign to the brokers
  nodeIds: "[0,1,2]"

  storage:
    # -- Storage size for the brokers
    size: 1.5Ti

    # -- Storage class to use when requesting persistent volumes
    # @default -- None, use the default storage class
    storageClassName: ""

  # -- Affinity for broker pod assignment
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: "app.kubernetes.io/name"
                operator: In
                values:
                  - kafka
          topologyKey: "kubernetes.io/hostname"

  # -- Tolerations for broker pod assignment
  tolerations: []

  # -- Kubernetes resources for the brokers
  resources:
    requests:
      memory: 4Gi
      cpu: 1
    limits:
      memory: 8Gi
      cpu: 2

cruiseControl:
  # -- Enable cruise control (required for broker migration and rebalancing)
  enabled: false

  # -- Maximum number of replicas per broker
  maxReplicasPerBroker: 20000

brokerMigration:
  # -- Whether to enable another node pool to migrate the kafka brokers to
  enabled: false

  # -- Name of the node pool
  name: broker-migration

  # -- IDs to assign to the brokers
  nodeIDs: "[6,7,8]"

  # -- Storage size for the brokers
  size: 1.5Ti

  # -- Storage class name for the brokers
  # @default -- None, use the default storage class
  storageClassName: ""

  rebalance:
    # -- Whether to rebalance the kafka cluster
    enabled: false

    # -- Brokers to avoid during rebalancing
    # These are the brokers you are migrating from and you want to remove
    # after the migration is complete.
    avoidBrokers:
      - 0
      - 1
      - 2

  # -- Affinity for Kafka broker pod assignment
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: "app.kubernetes.io/name"
                operator: In
                values:
                  - kafka
          topologyKey: "kubernetes.io/hostname"


  # -- Tolerations for Kafka broker pod assignment
  tolerations: []

kafkaExporter:
  # -- Enable Kafka exporter
  enabled: false

  # -- Kafka topics to monitor
  topicRegex: ".*"

  # -- Consumer groups to monitor
  groupRegex: ".*"

  # -- Logging level
  logging: info

  # -- Enable Sarama logging for pod
  enableSaramaLogging: false

  # -- Whether to show all offsets or just offsets from connected groups
  showAllOffsets: true

  # -- Kubernetes requests and limits for the Kafka exporter
  # @default -- See `values.yaml`
  resources:
    requests:
      memory: 512Mi
      cpu: 1
    limits:
      memory: 1Gi
      cpu: 2

connect:
  # -- Enable Kafka Connect
  enabled: false

  # -- Custom strimzi-kafka image with connector plugins used by sasquatch
  image: ghcr.io/lsst-sqre/strimzi-0.40.0-kafka-3.7.0:tickets-DM-43491

  # -- Number of Kafka Connect replicas to run
  replicas: 3

  config:
    # -- Set the converter for the message ke
    key.converter: io.confluent.connect.avro.AvroConverter

    # -- Enable converted schemas for the message key
    key.converter.schemas.enable: true

    # -- URL for the schema registry
    key.converter.schema.registry.url: http://sasquatch-schema-registry.sasquatch:8081

    # -- Converter for the message value
    value.converter: io.confluent.connect.avro.AvroConverter

    # -- Enable converted schemas for the message value
    value.converter.schemas.enable: true

    # -- URL for the schema registry
    value.converter.schema.registry.url: http://sasquatch-schema-registry.sasquatch:8081

  # -- Kubernetes requests and limits for Kafka Connect
  # @default -- See `values.yaml`
  resources:
    requests:
      memory: 2Gi
      cpu: 1
    limits:
      memory: 4Gi
      cpu: 2

registry:
  ingress:
    # -- Whether to enable an ingress for the Schema Registry
    enabled: false

    # -- Hostname for the Schema Registry
    # @default -- None, must be set if ingress is enabled
    hostname: ""

    # -- Annotations that will be added to the Ingress resource
    annotations: {}

  # -- Name of the topic used by the Schema Registry
  schemaTopic: registry-schemas

  # -- Kubernetes requests and limits for the Schema Registry
  # @default -- See `values.yaml`
  resources:
    requests:
      memory: 1Gi
      cpu: 100m
    limits:
      memory: 2Gi
      cpu: 1


# -- A list of usernames for users who should have global admin permissions.
# These users will be created, along with their credentials.
superusers:
  - kafka-admin

users:
  replicator:
    # -- Enable user replicator (used by Mirror Maker 2 and required at both
    # source and target clusters)
    enabled: false

  telegraf:
    # -- Enable user telegraf (deployed by parent Sasquatch chart)
    enabled: false

mirrormaker2:
  # -- Enable replication in the target (passive) cluster
  enabled: false

  # -- Number of Mirror Maker replicas to run
  replicas: 3

  source:
    # -- Source (active) cluster to replicate from
    # @default -- None, must be set if enabled
    bootstrapServer: ""

    # -- Topic replication from the source cluster defined as a
    # comma-separated list or regular expression pattern
    topicsPattern: "registry-schemas, lsst.sal.*"

  replication:
    policy:
      # -- Convention used to rename topics when the DefaultReplicationPolicy
      # replication policy is used. Default is "" when the
      # IdentityReplicationPolicy replication policy is used.
      separator: ""

      # -- Replication policy.
      class: "org.apache.kafka.connect.mirror.IdentityReplicationPolicy"

  # -- Kubernetes resources for MirrorMaker2
  resources:
    requests:
      memory: 2Gi
      cpu: 500m
    limits:
      memory: 4Gi
      cpu: 1
