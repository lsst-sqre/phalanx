# Default values for Kafka used in Sasquatch.

cluster:
  # -- Name used for the Kafka cluster, and used by Strimzi for many
  # annotations
  name: sasquatch

  # -- Site wide label required for gathering Prometheus metrics if they are
  # enabled
  monitorLabel: {}

kafka:
  # -- Version of Kafka to deploy
  version: "3.8.0"

  # -- Number of Kafka broker replicas to run
  replicas: 3

  # -- The minimum number of in-sync replicas that must be available for the producer to successfully send records
  # Cannot be greater than the number of replicas.
  minInsyncReplicas: 2

  storage:
    # -- Size of the backing storage disk for each of the Kafka brokers
    size: 500Gi

    # -- Name of a StorageClass to use when requesting persistent volumes
    storageClassName: ""

  config:
    # -- Number of minutes for a consumer group's offsets to be retained
    # @default -- 4320 minutes (3 days)
    offsets.retention.minutes: 4320

    # -- Number of days for a topic's data to be retained
    # @default -- 4320 minutes (3 days)
    log.retention.minutes: 4320

    # -- The largest record batch size allowed by Kafka
    message.max.bytes: 10485760

    # -- The number of bytes of messages to attempt to fetch for each partition
    replica.fetch.max.bytes: 10485760

  metricsConfig:
    # -- Whether metric configuration is enabled
    enabled: false

  listeners:
    plain:
      # -- Whether internal plaintext listener is enabled
      enabled: false

    tls:
      # -- Whether internal TLS listener is enabled
      enabled: false

    external:
      # -- Whether external listener is enabled
      enabled: false

  externalListener:
    tls:
      # -- Whether TLS encryption is enabled
      enabled: false

      # -- Name of a ClusterIssuer capable of provisioning a TLS certificate
      # for the broker
      certIssuerName: "letsencrypt-dns"

    bootstrap:
      # Load balancer IP configuration
      #
      # The loadbalancer is requested with the IP address specified in this
      # field.  This feature depends on whether the underlying cloud provider
      # supports specifying the loadBalancerIP when a load balancer is
      # created.  This field is ignored if the cloud provider does not support
      # the feature.
      #
      # Once the IP address is provisioned this option make it possible to pin
      # the IP address.  We can request the same IP next time it is
      # provisioned. This is important because it lets us configure a DNS
      # record, associating a hostname with that pinned IP address.
      #
      # -- Request this load balancer IP. See `values.yaml` for more
      # discussion
      # @default -- Do not request a load balancer IP
      loadBalancerIP: ""

      # -- Name used for TLS hostname verification
      # @default -- Do not configure TLS
      host: ""

      # -- Annotations that will be added to the Ingress, Route, or Service
      # resource
      annotations: {}

    # -- Brokers configuration. _host_ is used in the brokers'
    # advertised.brokers configuration and for TLS hostname verification.  The
    # format is a list of maps.
    brokers: []
    # For example:
    # brokers:
    #   - broker: 0
    #     loadBalancerIP: "192.168.1.1"
    #     host: broker-0.example
    #     annotations:
    #       metallb.universe.tf/address-pool: sdf-dmz
    #   - broker: 1
    #     loadBalancerIP: "192.168.1.2"
    #     host: broker-1.example
    #     annotations:
    #       metallb.universe.tf/address-pool: sdf-dmz

  # -- Affinity for Kafka pod assignment
  # @default -- See `values.yaml`
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: "app.kubernetes.io/name"
                operator: In
                values:
                  - kafka
          topologyKey: "kubernetes.io/hostname"

  # -- Tolerations for Kafka broker pod assignment
  tolerations: []

  # -- Kubernetes requests and limits for the Kafka brokers
  # @default -- See `values.yaml`
  resources:
    requests:
      memory: 32Gi
      cpu: "4"
    limits:
      memory: 64Gi
      cpu: "8"

kraft:
  # -- Enable KRaft mode for Kafka
  enabled: false

kafkaController:
  # -- Enable Kafka Controller
  enabled: false

  storage:
    # -- Size of the backing storage disk for each of the Kafka controllers
    size: 20Gi

    # -- Name of a StorageClass to use when requesting persistent volumes
    storageClassName: ""

  # -- Kubernetes requests and limits for the Kafka Controller
  # @default -- See `values.yaml`
  resources:
    requests:
      memory: 32Gi
      cpu: "4"
    limits:
      memory: 64Gi
      cpu: "8"

kafkaExporter:
  # -- Enable Kafka exporter
  enabled: false

  # -- Kafka topics to monitor
  topicRegex: ".*"

  # -- Consumer groups to monitor
  groupRegex: ".*"

  # -- Logging level
  logging: info

  # -- Enable Sarama logging for pod
  enableSaramaLogging: false

  # -- Kubernetes requests and limits for the Kafka exporter
  # @default -- See `values.yaml`
  resources:
    limits:
      cpu: "1"
      memory: "256Mi"
    requests:
      cpu: "375m"
      memory: "100Mi"

connect:
  # -- Enable Kafka Connect
  enabled: false

  # -- Custom strimzi-kafka image with connector plugins used by sasquatch
  image: ghcr.io/lsst-sqre/strimzi-0.40.0-kafka-3.7.0:tickets-DM-43491

  # -- Number of Kafka Connect replicas to run
  replicas: 3

  config:
    # -- Set the converter for the message ke
    key.converter: io.confluent.connect.avro.AvroConverter

    # -- Enable converted schemas for the message key
    key.converter.schemas.enable: true

    # -- URL for the schema registry
    key.converter.schema.registry.url: http://sasquatch-schema-registry.sasquatch:8081

    # -- Converter for the message value
    value.converter: io.confluent.connect.avro.AvroConverter

    # -- Enable converted schemas for the message value
    value.converter.schemas.enable: true

    # -- URL for the schema registry
    value.converter.schema.registry.url: http://sasquatch-schema-registry.sasquatch:8081

registry:
  ingress:
    # -- Whether to enable an ingress for the Schema Registry
    enabled: false

    # -- Hostname for the Schema Registry
    # @default -- None, must be set if ingress is enabled
    hostname: ""

    # -- Annotations that will be added to the Ingress resource
    annotations: {}

  # -- Name of the topic used by the Schema Registry
  schemaTopic: registry-schemas

  # -- Kubernetes requests and limits for the Schema Registry
  # @default -- See `values.yaml`
  resources:
    requests:
      memory: "128Mi"
      cpu: "5m"
    limits:
      memory: "2Gi"
      cpu: "1"


# -- A list of usernames for users who should have global admin permissions.
# These users will be created, along with their credentials.
superusers:
  - kafka-admin

users:
  replicator:
    # -- Enable user replicator (used by Mirror Maker 2 and required at both
    # source and target clusters)
    enabled: false

  camera:
    # -- Enable user camera, used at the camera environments
    enabled: false

  tsSalKafka:
    # -- Enable user ts-salkafka, used at the telescope environments
    enabled: false

    # -- Create lsst.s3.* related topics for the ts-salkafka user.
    topics: []

  kafdrop:
    # -- Enable user Kafdrop (deployed by parent Sasquatch chart).
    enabled: false

  telegraf:
    # -- Enable user telegraf (deployed by parent Sasquatch chart)
    enabled: false

  promptProcessing:
    # -- Enable user prompt-processing
    enabled: false

  kafkaConnectManager:
    # -- Enable user kafka-connect-manager
    enabled: false

  consdb:
    # -- Enable user consdb
    enabled: false


mirrormaker2:
  # -- Enable replication in the target (passive) cluster
  enabled: false

  # -- Number of Mirror Maker replicas to run
  replicas: 3

  source:
    # -- Source (active) cluster to replicate from
    # @default -- None, must be set if enabled
    bootstrapServer: ""

    # -- Topic replication from the source cluster defined as a
    # comma-separated list or regular expression pattern
    topicsPattern: "registry-schemas, lsst.sal.*"

  replication:
    policy:
      # -- Convention used to rename topics when the DefaultReplicationPolicy
      # replication policy is used. Default is "" when the
      # IdentityReplicationPolicy replication policy is used.
      separator: ""

      # -- Replication policy.
      class: "org.apache.kafka.connect.mirror.IdentityReplicationPolicy"

# -- Configuration for the Kafka Cruise Control
cruiseControl:
  enabled: false

# -- Configuration for deploying Kafka brokers with local storage
brokerStorage:
  enabled: false
  migration:
    enabled: false
    rebalance: false
    brokers:
      - 0
      - 1
      - 2
  size: 1.5Ti
  storageClassName: localdrive
