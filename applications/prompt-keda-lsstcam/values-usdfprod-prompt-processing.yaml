prompt-keda:
  image:
    pullPolicy: IfNotPresent
    tag: 6.9.0

  alerts:
    username: kafka-admin
    server: usdf-alert-stream-dev.lsst.cloud:9094
    topic: lsst-alerts-v7.4

  worker:
    # TODO: need to adjust this once we know how leaky the LSSTCam pipeline is
    # restart: 7
    # Expect much less memory usage/leakage for Single-Frame only
    restart: 30

  instrument:
    pipelines:
      # IMPORTANT: don't use flow-style mappings (i.e., {}) in pipelines specs
      # if the result (including any comments) is longer than 72 characters.
      # The config will get corrupted after template substitution.
      # Block-style mappings can have lines of any length.
      main: |-
        - survey: BLOCK-365  # FBS SV Field Survey
          pipelines:
          # TODO: enable ApPipe only when we're ready (resources, alerts, etc.)
          - ${PROMPT_PROCESSING_DIR}/pipelines/LSSTCam/SingleFrame.yaml
          - ${PROMPT_PROCESSING_DIR}/pipelines/LSSTCam/Isr.yaml
        - survey: BLOCK-T427  # Daytime checkout
          pipelines: ['${PROMPT_PROCESSING_DIR}/pipelines/LSSTCam/Isr-cal.yaml']
        # Produces nextVisits but not images
        - {survey: "BLOCK-T454", pipelines: []}
        # Miscellaneous scripts, not always images
        - {survey: "", pipelines: []}
        # Ignore unknown events during Commissioning
        - {pipelines: []}
      preprocessing: |-
        # Run to enable solar system processing in SingleFrame
        - survey: BLOCK-365
          pipelines: ['${PROMPT_PROCESSING_DIR}/pipelines/LSSTCam/Preprocessing.yaml']
        - {survey: "", pipelines: []}
        # Don't preprocess anything unknown
        - {pipelines: []}
    preloadPadding: 50.1
    calibRepo: s3://rubin-summit-users

  s3:
    imageBucket: rubin-summit
    endpointUrl: https://sdfembs3.sdf.slac.stanford.edu

  raw_microservice: http://172.24.5.158:8080/presence

  # TODO: replace with permanent service once it's up
  mpSky_service: http://sdfiana014.sdf.slac.stanford.edu:3666/ephemerides/

  imageNotifications:
    kafkaClusterAddress: prompt-processing-2-kafka-bootstrap.kafka:9092
    topic: rubin-summit-notification
    # TODO: need to adjust this based on observed nextVisit lead time (depends on scheduler) and PP prep time
    # The shorter this is, the less capacity is wasted on canceled visits
    imageTimeout: 120

  apdb:
    config: s3://rubin-summit-users/apdb_config/cassandra/pp_apdb_lsstcam.yaml

  logLevel: timer.lsst.activator=DEBUG timer.lsst.daf.butler=VERBOSE lsst.associateApdb=VERBOSE lsst.computeReliability=VERBOSE lsst.daf.butler=VERBOSE

  sasquatch:
    # TODO: production Sasquatch not yet ready
    endpointUrl: https://usdf-rsp-dev.slac.stanford.edu/sasquatch-rest-proxy
    namespace: lsst.prompt.prod
    auth_env: false

  keda:
    minReplicaCount: 3
    # TODO: this is scaled for SingleFrame, with 25% margin
    maxReplicaCount: 1100
    # TODO: may need to override for debugging
    # failedJobsHistoryLimit: 100

    # TODO: may need to reduce if we don't have enough capacity
    # redisStreams:
    #   expiration: 600

  initializer:
    # 6 retries is not enough time to fix, e.g., DB permissions problems
    retries: 15

    podAnnotations: {
      edu.stanford.slac.sdf.project/usdf-embargo: "true"
    }

  podAnnotations: {
    edu.stanford.slac.sdf.project/usdf-embargo: "true"
  }

  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 10
        preference:
          matchExpressions:
          - key: node-role.kubernetes.io/prompt-processing
            operator: Exists
