# Default values for butler.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- Number of web deployment pods to start
replicaCount: 1

image:
  # -- Image to use in the butler deployment
  repository: "ghcr.io/lsst/daf_butler"

  # -- Pull policy for the butler image
  pullPolicy: "IfNotPresent"

  # -- Overrides the image tag whose default is the chart appVersion.
  tag: ""

ingress:
  # -- Additional annotations for the ingress rule
  annotations: {}

autoscaling:
  # -- Enable autoscaling of butler deployment
  enabled: true

  # -- Minimum number of butler deployment pods
  minReplicas: 1

  # -- Maximum number of butler deployment pods
  #
  # Each replica can have 40 database connections, so we need to make sure the
  # combined connections are under the postgres connection limit. (Which is
  # configurable, but currently set to 400 at the IDF.)
  maxReplicas: 10

  # -- Target CPU utilization of butler deployment pods
  #
  # Butler CPU usage is very low in normal operation because most things are
  # I/O bound.  CPU usage can start creeping up if we have many queries running
  # simultaneously (due to serialization overhead and spatial postprocessing.)
  # In this case the thread pool and database connection pool are probably
  # oversubscribed long before we hit 100% cpu usage, so we want to get more
  # replicas up at fairly low CPU usage.
  targetCPUUtilizationPercentage: 25
  # targetMemoryUtilizationPercentage: 80

# -- Annotations for the butler deployment pod
podAnnotations: {}

# -- Resource limits and requests for the butler deployment pod
# @default -- see `values.yaml`
resources:
  limits:
    cpu: "1"
    # Worst case peak usage for a single container would be something like all
    # 40 threads in the thread pool running large queries costing ~35MB each.
    memory: "1.5Gi"
  requests:
    cpu: "1"
    # Butler server uses around 200MB idle at startup, but under dynamic usage
    # Python seems to want to hold onto another couple hundred megabytes of
    # heap.
    memory: "0.5Gi"

# -- Node selection rules for the butler deployment pod
nodeSelector: {}

# -- Tolerations for the butler deployment pod
tolerations: []

# -- Affinity rules for the butler deployment pod
affinity: {}

# The following will be set by parameters injected by Argo CD and should not
# be set in the individual environment values files.
global:
  # -- Base URL for the environment
  # @default -- Set by Argo CD
  baseUrl: ""

  # -- Host name for ingress
  # @default -- Set by Argo CD
  host: ""

  # -- Base path for Vault secrets
  # @default -- Set by Argo CD
  vaultSecretsPath: ""

config:
  # -- Mapping from Butler repository label to Butler configuration URI for
  # repositories which will be hosted by this server.
  repositories: {}

  # -- Postgres connection string pointing to the registry database hosting
  # Data Preview 0.2 data.
  # @default -- No configuration file for DP02 will be generated.
  dp02PostgresUri: ""

  # -- Postgres connection string pointing to the registry database hosting
  # Data Preview 1 data.
  # @default -- No configuration file for DP1 will be generated.
  dp1PostgresUri: ""

  # -- True if the 'dp02' Butler repository alias should use client/server
  # Butler.  False if it should use DirectButler.
  dp02ClientServerIsDefault: false

  # -- True if the 'dp02' datastore files should be served from SLAC, false
  # if they should be served from Google.
  dp02UseSlacDatastore: false

  # -- Postgres username used to connect to the Butler DB
  # @default -- Use values specified in per-repository Butler config files.
  pguser: ""

  # -- URL for the primary S3 service where files for datasets are stored by Butler.
  s3EndpointUrl: ""

  # -- Endpoint URLs for additional S3 services used by the Butler, as a
  # mapping from profile name to URL.
  # @default -- No additional URLs
  additionalS3EndpointUrls: {}

  # -- The prefix of the path portion of the URL where the Butler service will
  # be exposed.  For example, if the service should be exposed at
  # `https://data.lsst.cloud/api/butler`, this should be set to `/api/butler`
  pathPrefix: "/api/butler"

  # -- If true, borrow the S3 and Postgres secrets set up in Nublado for
  # end-users.  Otherwise, use secrets specifically set up for the Butler
  # server.
  shareNubladoSecrets: true
